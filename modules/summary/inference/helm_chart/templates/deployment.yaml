apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Values.service.name }}
  namespace: {{ .Values.service.namespace }}
  labels:
    app: {{ .Values.service.name }}
spec:
  replicas: {{ .Values.replicas.min }}
  selector:
    matchLabels:
      app: {{ .Values.service.name }}
  template:
    metadata:
      labels:
        app: {{ .Values.service.name }}
    spec:
      nodeSelector:
        node_pool: "{{ .Values.nodeSelector.node }}"
      tolerations:
        - key: "nvidia.com/gpu"
          value: "present"
          effect: "NoSchedule"
      initContainers:
        {{- if .Values.waitForDependencies }}
        - name: wait-for-cache
          image: {{ .Values.busybox.repository }}:{{ .Values.busybox.tag }}
          imagePullPolicy: "{{ .Values.busybox.pull }}"
          command: ['sh', '-c', "until nc -z {{ .Values.dependencies.cache }}; do echo waiting for cache; sleep 2; done"]
        {{- end }}
        {{- if .Values.createSymlink }}
        - name: create-symlink
          image: {{ .Values.busybox.repository }}:{{ .Values.busybox.tag }}
          imagePullPolicy: "{{ .Values.busybox.pull }}"
          command: ["/bin/sh", "-c", "--"]
          args: ["echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh"]
          securityContext:
            privileged: true
          resources:
            requests:
              cpu: 10m
              memory: 50Mi
          volumeMounts:
            - name: {{ .Values.service.name }}
              mountPath: /scripts/ldconfig_symlink.sh
              subPath: ldconfig_symlink.sh
            - name: host-sbin
              mountPath: /host-sbin
            - name: host-usr-sbin
              mountPath: /host-usr-sbin
            - name: host-bin
              mountPath: /host-bin
            - name: host-usr-bin
              mountPath: /host-usr-bin
        {{- end }}
        {{- if not .Values.local }}
        - name: update-permissions
          image: {{ .Values.busybox.repository }}:{{ .Values.busybox.tag }}
          imagePullPolicy: "{{ .Values.busybox.pull }}"
          command:
            - /bin/sh
            - -c
            - |
              chown -R {{ .Values.securityContext.runAsUser }}:{{ .Values.securityContext.runAsGroup }} /workspace/hf_models_cache && chmod -R 777 /workspace/hf_models_cache
          securityContext:
            privileged: true
          volumeMounts:
            - name: model-volume
              mountPath: /workspace/hf_models_cache
        - name: download-model
          image: {{ .Values.busybox.repository }}:{{ .Values.busybox.tag }}
          imagePullPolicy: "{{ .Values.busybox.pull }}"
          command:
            - /bin/sh
            - -c
            - |
              download_and_extract_model() {
                echo "Model downloading started..."

                touch /workspace/hf_models_cache/downloading

                echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                  'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/model.tar.gz.part.$PART; \
                  while [ $RETRIES -lt $MAX_RETRIES ]; do \
                    echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                    wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                    echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                  done; \
                  [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                  echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                rm /workspace/hf_models_cache/summary.tar.*
                rm /workspace/hf_models_cache/downloading
                touch /workspace/hf_models_cache/complete
              }
              if [ ! -f /workspace/hf_models_cache/complete ]; then
                if [ ! -f /workspace/hf_models_cache/downloading ]; then
                  download_and_extract_model
                else
                  echo "Download in progress by another pod. Waiting..."
                  while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete ]; do
                    sleep $((3 + RANDOM % 2))
                  done

                  if [ ! -f /workspace/hf_models_cache/complete ]; then
                    download_and_extract_model
                  else
                    echo "Model cache ready."
                  fi
                fi
              else
                echo "Model cache already exists. Skipping download."
              fi

              echo "Model load done."
          securityContext:
            runAsUser: {{ .Values.securityContext.runAsUser }}
            runAsGroup: {{ .Values.securityContext.runAsGroup }}
          volumeMounts:
            - name: model-volume
              mountPath: /workspace/hf_models_cache
        {{- end }}
      containers:
        - name: {{ .Values.service.name }}
          image: {{ .Values.image.repository }}:{{ .Values.image.tag }}
          imagePullPolicy: "{{ .Values.image.pull }}"
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
          workingDir: /workspace
          command:
            - /bin/bash
            - -c
            - |
              export PYTHONPATH=/workspace:/workspace/vllm:$PYTHONPATH && supervisord -c /workspace/supervisord.conf
          securityContext:
            runAsUser: {{ .Values.securityContext.runAsUser }}
            runAsGroup: {{ .Values.securityContext.runAsGroup }}
          livenessProbe:
            httpGet:
              path: /alive
              port: 8080
            initialDelaySeconds: 30
            failureThreshold: 8
            periodSeconds: 15
          readinessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 180
            failureThreshold: 20
            periodSeconds: 15
          {{- if not .Values.local }}
          resources:
            limits:
              cpu: "{{ .Values.resources.limits.cpu }}"
              memory: "{{ .Values.resources.limits.memory }}"
            requests:
              cpu: "{{ .Values.resources.requests.cpu }}"
              memory: "{{ .Values.resources.requests.memory }}"
          {{- end }}
          volumeMounts:
            - name: config-models
              mountPath: /workspace/config_models.py
              subPath: config_models.py
            - name: config-volume
              mountPath: /workspace/config.py
              subPath: config.py
            - name: supervisord-volume
              mountPath: /workspace/supervisord.conf
              subPath: supervisord.conf
            {{- if not .Values.local }}
            - name: model-volume
              mountPath: /workspace/hf_models_cache
            {{- end }}
      volumes:
        - name: config-models
          configMap:
            name: config-models-map
        - name: config-volume
          configMap:
            name: summary-config-py-map
        - name: supervisord-volume
          configMap:
            name: summary-supervisord-24gb-conf-map
        {{- if .Values.createSymlink }}
        - name: {{ .Values.service.name }}
          configMap:
            name: ldconfig-symlink-map
            defaultMode: 0555
        - name: host-sbin
          hostPath:
            path: /sbin
            type: Directory
        - name: host-usr-sbin
          hostPath:
            path: /usr/sbin
            type: Directory
        - name: host-bin
          hostPath:
            path: /bin
            type: Directory
        - name: host-usr-bin
          hostPath:
            path: /usr/bin
            type: Directory
        {{- end }}
        {{- if not .Values.local }}
        - name: model-volume
          persistentVolumeClaim:
            claimName: {{ .Values.pv.name }}
        {{- end }}